#!/usr/bin/env python3
"""
Expected Information Gain Reasoning (EIG-R) - Usage Example and Testing

This script demonstrates how to use the EIG-based reasoning extension
and provides comprehensive testing and validation functionality.

Mathematical Framework:
- EIG_t = H_t - E[H_{t+1} | H_t]
- Continue reasoning iff EIG_t > Î» (lambda_cost threshold)
- H_t: Current answer posterior entropy
- E[H_{t+1} | H_t]: Expected entropy after one more reasoning step

Usage Examples:
1. Basic EIG reasoning with default parameters
2. Advanced EIG reasoning with custom parameters  
3. Comparative analysis against other scaling methods
4. Performance profiling and metrics analysis
"""

import os
import sys
import time
import json
from typing import Dict, Any, List

# Add the parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from lm_eval.budget_forcing.scalers import (
    expected_information_gain_reasoning,
    get_eig_metrics_summary,
    print_eig_metrics
)


def example_usage_basic():
    """
    Example 1: Basic EIG Reasoning
    
    Demonstrates the simplest way to use EIG reasoning with default parameters.
    """
    print("="*80)
    print("EXAMPLE 1: BASIC EIG REASONING")
    print("="*80)
    
    # Basic configuration for EIG reasoning
    eig_config = {
        "scale_func_name": "expected_information_gain_reasoning",
        "lambda_cost": 0.05,  # Information cost threshold
        "beam_size": 8,       # Number of answer candidates
        "mc_samples": 5,      # Monte Carlo samples for forecasting
    }
    
    print("Basic EIG Configuration:")
    for key, value in eig_config.items():
        print(f"  {key}: {value}")
    
    print("\nTo use this in lm_eval, add to gen_kwargs:")
    print("--gen_kwargs \"" + ",".join([f"{k}={v}" for k, v in eig_config.items()]) + "\"")
    
    print("\nExample command:")
    print("lm_eval \\")
    print("    --model hf \\")
    print("    --model_args pretrained=simplescaling/s1.1-1.5B,dtype=float16 \\")
    print("    --tasks aime24_nofigures \\")
    print("    --batch_size auto \\")
    print("    --apply_chat_template \\")
    print("    --gen_kwargs \"max_gen_toks=32768,max_tokens_thinking=auto,thinking_n_ignore=6,scale_func_name=expected_information_gain_reasoning,lambda_cost=0.05,beam_size=8,mc_samples=5\"")


def example_usage_advanced():
    """
    Example 2: Advanced EIG Reasoning
    
    Demonstrates advanced configuration with custom parameters for different
    computational budgets and problem types.
    """
    print("\n" + "="*80)
    print("EXAMPLE 2: ADVANCED EIG REASONING CONFIGURATIONS")
    print("="*80)
    
    # Configuration for different scenarios
    configs = {
        "high_precision": {
            "description": "High precision for complex mathematical problems",
            "lambda_cost": 0.02,        # Lower threshold = more reasoning
            "beam_size": 12,            # More answer candidates
            "mc_samples": 8,            # More Monte Carlo samples
            "sample_length": 128,       # Longer sample continuations
            "max_computation_time": 60  # Longer computation budget
        },
        
        "balanced": {
            "description": "Balanced performance for general reasoning",
            "lambda_cost": 0.05,        # Standard threshold
            "beam_size": 8,             # Standard beam size
            "mc_samples": 5,            # Standard MC samples
            "sample_length": 64,        # Standard sample length
            "max_computation_time": 30  # Standard time budget
        },
        
        "fast": {
            "description": "Fast execution for time-constrained scenarios",
            "lambda_cost": 0.1,         # Higher threshold = less reasoning
            "beam_size": 4,             # Fewer answer candidates
            "mc_samples": 3,            # Fewer MC samples
            "sample_length": 32,        # Shorter sample continuations
            "max_computation_time": 15  # Shorter time budget
        }
    }
    
    for config_name, config in configs.items():
        print(f"\nðŸ“Š {config_name.upper()} CONFIGURATION:")
        print(f"   Description: {config['description']}")
        
        # Remove description for gen_kwargs
        gen_kwargs = {k: v for k, v in config.items() if k != 'description'}
        gen_kwargs["scale_func_name"] = "expected_information_gain_reasoning"
        
        print("   Parameters:")
        for key, value in gen_kwargs.items():
            print(f"     {key}: {value}")
        
        print("   Gen kwargs string:")
        kwargs_str = ",".join([f"{k}={v}" for k, v in gen_kwargs.items()])
        print(f"     \"{kwargs_str}\"")


def example_comparative_analysis():
    """
    Example 3: Comparative Analysis
    
    Shows how to compare EIG reasoning against other scaling methods.
    """
    print("\n" + "="*80)
    print("EXAMPLE 3: COMPARATIVE ANALYSIS SETUP")
    print("="*80)
    
    comparison_configs = {
        "baseline_fixed": {
            "description": "Fixed budget forcing (S1 baseline)",
            "scale_func_name": "default",
            "thinking_n_ignore": 6
        },
        
        "entropy_threshold": {
            "description": "Entropy-based thresholding",
            "scale_func_name": "entropy_thresholding",
            "threshold": 0.5,
            "decay_factor": 1.0,
            "last_k": -1
        },
        
        "stepwise_uncertainty": {
            "description": "Step-wise uncertainty driven",
            "scale_func_name": "step_wise_uncertainty_driven",
            "max_steps": 10,
            "step_selection_strategy": "highest_uncertainty",
            "use_min_uncertainty_filter": True,
            "min_step_uncertainty": 0.3
        },
        
        "eig_reasoning": {
            "description": "Expected Information Gain reasoning",
            "scale_func_name": "expected_information_gain_reasoning",
            "lambda_cost": 0.05,
            "beam_size": 8,
            "mc_samples": 5,
            "sample_length": 64
        }
    }
    
    print("Comparative Analysis Configurations:")
    for method_name, config in comparison_configs.items():
        print(f"\nðŸ”¬ {method_name.upper()}:")
        print(f"   Description: {config['description']}")
        
        gen_kwargs = {k: v for k, v in config.items() if k != 'description'}
        kwargs_str = ",".join([f"{k}={v}" for k, v in gen_kwargs.items()])
        print(f"   Gen kwargs: \"{kwargs_str}\"")
    
    print("\nðŸ“ˆ EVALUATION METRICS TO COMPARE:")
    print("   - Answer accuracy")
    print("   - Average tokens per problem")
    print("   - Computation time per problem")
    print("   - Token efficiency (accuracy / tokens)")
    print("   - Reasoning depth distribution")


def example_metrics_analysis():
    """
    Example 4: Metrics Analysis
    
    Demonstrates how to analyze EIG reasoning performance and behavior.
    """
    print("\n" + "="*80)
    print("EXAMPLE 4: METRICS ANALYSIS AND MONITORING")
    print("="*80)
    
    print("ðŸ“Š AVAILABLE METRICS:")
    print("   1. Information Gain Statistics:")
    print("      - Mean, std, min, max EIG values")
    print("      - Distribution of information gains")
    print("   2. Decision Statistics:")
    print("      - Continue vs stop rate")
    print("      - Decision consistency")
    print("   3. Timing Statistics:")
    print("      - Component-wise computation times")
    print("      - Total processing time")
    print("   4. Failure Analysis:")
    print("      - Success/failure rates")
    print("      - Failure type breakdown")
    
    print("\nðŸ”§ HOW TO ACCESS METRICS:")
    print("   After running evaluation with EIG reasoning:")
    print("   ```python")
    print("   from lm_eval.budget_forcing.scalers import print_eig_metrics")
    print("   print_eig_metrics()  # Print comprehensive summary")
    print("   ```")
    
    print("\nðŸ“ˆ PERFORMANCE OPTIMIZATION TIPS:")
    print("   1. Tune lambda_cost based on compute budget:")
    print("      - Lower Î»: More reasoning, higher accuracy")
    print("      - Higher Î»: Less reasoning, faster execution")
    print("   2. Adjust beam_size for answer complexity:")
    print("      - Math problems: 8-12 candidates")
    print("      - Multiple choice: 4-6 candidates")
    print("   3. Balance mc_samples vs computation time:")
    print("      - More samples: Better forecasting")
    print("      - Fewer samples: Faster execution")


def validate_eig_implementation():
    """
    Validation suite for EIG implementation.
    
    Tests various components and edge cases to ensure correctness.
    """
    print("\n" + "="*80)
    print("EIG IMPLEMENTATION VALIDATION")
    print("="*80)
    
    validation_tests = [
        {
            "name": "Parameter Validation",
            "description": "Test parameter bounds and validation",
            "status": "Manual verification required"
        },
        {
            "name": "Numerical Stability",
            "description": "Test entropy calculations with edge cases",
            "status": "Implemented with eps safeguards"
        },
        {
            "name": "Error Handling",
            "description": "Test graceful failure and fallback mechanisms",
            "status": "Comprehensive error wrapping implemented"
        },
        {
            "name": "Integration Test",
            "description": "Test integration with existing budget forcing",
            "status": "Ready for testing"
        },
        {
            "name": "Performance Test",
            "description": "Benchmark computation time and memory usage",
            "status": "Manual profiling recommended"
        }
    ]
    
    print("Validation Test Status:")
    for i, test in enumerate(validation_tests, 1):
        print(f"{i}. {test['name']}")
        print(f"   Description: {test['description']}")
        print(f"   Status: {test['status']}")
        print()


def main():
    """Main function demonstrating all EIG reasoning examples."""
    print("ðŸ”¬ EXPECTED INFORMATION GAIN REASONING (EIG-R)")
    print("Complete Usage Guide and Examples")
    print("="*80)
    
    # Run all examples
    example_usage_basic()
    example_usage_advanced()
    example_comparative_analysis()
    example_metrics_analysis()
    validate_eig_implementation()
    
    print("\n" + "="*80)
    print("ðŸŽ¯ QUICK START SUMMARY")
    print("="*80)
    print("1. Add to your lm_eval command:")
    print("   --gen_kwargs \"scale_func_name=expected_information_gain_reasoning,lambda_cost=0.05\"")
    print("2. Monitor performance with:")
    print("   from lm_eval.budget_forcing.scalers import print_eig_metrics; print_eig_metrics()")
    print("3. Tune lambda_cost based on your compute budget and accuracy requirements")
    print("4. Experiment with beam_size and mc_samples for optimal performance")
    
    print("\nðŸ“š MATHEMATICAL FOUNDATION:")
    print("   EIG_t = H_t - E[H_{t+1} | H_t]")
    print("   Continue reasoning iff EIG_t > Î»")
    print("   Maximizes mutual information per unit cost")
    
    print("\nâœ¨ Ready to enhance your test-time reasoning with principled information theory!")


if __name__ == "__main__":
    main() 